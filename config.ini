[server]
server_ai = ollama
; These params only for LM Studio
base_url = http://127.0.0.1:1234/
api_key = for_local_not_needed

[ai_config]
persona = lilith_persona.txt
memory = memory.json
ai_model = deepseek-r1
; ai_model = deepseek-r1  ;;; Ollama model
temperature = 0.85
max_tokens = 120

[lilith_display]
display_path = modules/viewer.py
revert_delay = 5
blink_min_interval = 4
blink_max_interval = 8
blink_duration = 0.25
assets_path = assets/
default_state = idle
; room / glass
place = room

[viewer_socket]
host = localhost
port = 8888